<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<title>Conference Papers</title>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<link href="css/font-awesome.min.css" rel="stylesheet" type="text/css" media="all">
		<link href="css/themify-icons.css" rel="stylesheet" type="text/css" media="all" />
		<link href="css/bootstrap.css" rel="stylesheet" type="text/css" media="all" />
		<link href="css/theme-fire.css" rel="stylesheet" type="text/css" media="all" />
		<link href="css/custom.css" rel="stylesheet" type="text/css" media="all" />
		<link href='https://fonts.googleapis.com/css?family=Lato:300,400%7CRaleway:100,400,300,500,600,700%7COpen+Sans:400,500,600' rel='stylesheet' type='text/css'>
		<link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,600,700" rel="stylesheet" type="text/css">
		<link href="css/font-roboto.css" rel="stylesheet" type="text/css">
		<link rel="apple-touch-icon" sizes="180x180" href="/img/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="/img/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/img/favicon-16x16.png">
		<link rel="manifest" href="/site.webmanifest">
	</head>

	<body class="boxed-layout btn-rounded">
		<div class="nav-container">
			<nav>
				<div class="left big-logo">
					<a href="index.html">
					<div class="vnu" >
						<img class="logo logo-dark" title="Robert Castle" src="img/logo.png">
					</div>
					</a>
				</div>
				<div class="nav-bar">
					<div class="module widget-handle mobile-toggle right visible-sm visible-xs">
						<i class="ti-menu"></i>
					</div>
					<div class="module-group right">
						<div class="module left">
							<ul class="menu">
								<li>
									<a href="index.html" target="_self">Home</a>
								</li>
								<li class="has-dropdown toggle-sub">
									<a href="#">Publications</a>
									<ul>
										<li>
											<a href="thesis.html" target="_self">Thesis</a>
										</li>
										<li>
											<a href="conference-papers.html" target="_self">Conference papers<br></a>
										</li>
										<li>
											<a href="journal-articles.html" target="_self">Journal Articles<br></a>
										</li>
									</ul>
								</li>
								<li>
									<a href="software.html" target="_self">Software<br></a>
								</li>
								<li class="vpf">
									<a href="contact.html" target="_self">Contact</a>
								</li>
							</ul>
						</div>
					</div>
				</div>
			</nav>
		</div>

		<div class="main-container">
			<section class="page-title page-title-4 bg-secondary">
				<div class="container">
					<div class="row">
						<div class="col-md-6">
							<h3 class="mb0 bold">Conference Papers</h3>
						</div>
					</div>
				</div>
			</section>

			<section>
				<div class="container">
					<div class="row">
						<div class="col-sm-10 col-sm-offset-1">
							<h3 class="uppercase color-primary mb40 mb-xs-24">Object Recognition and Localization While Tracking and Mapping</h3>
							<p class="lead">
								<b>R O Castle</b>, and D W Murray, Proc 8th IEEE/ACM International Symposium on Mixed and Augmented Reality, Orlando, Florida, Oct 19 – 22, 2009. <a href="https://doi.org/10.1109/ISMAR.2009.5336477">doi:10.1109/ISMAR.2009.5336477</a>
							</p>
							<p class="text-center">
								<a class="btn" href="http://www.robots.ox.ac.uk/~bob/publications/castle_murray_ismar2009/castle_murray_ismar2009.pdf">Paper</a>
								<a class="btn" href="http://www.robots.ox.ac.uk/~bob/publications/castle_murray_ismar2009/castle_murray_ismar2009_poster_A1.pdf">Poster</a>
							</p>
							<h4>Abstract</h4>
							<p>
							This paper demonstrates how objects can be recognized, reconstructed, and localized within a 3D map, using observations and matching of SIFT features in keyframes. The keyframes arise as part of a frame-rate process of parallel camera tracking and mapping, in which the keyframe camera poses and 3D map points are refined using bundle adjustment. The object reconstruction process runs independently, and in parallel to, the tracking and mapping processes. Detected objects are automatically labelled on the user’s display using predefined annotations. The annotations are also used to highlight areas of interest upon the objects to the user.
							</p>
						</div>
					</div>
				</div>
				
				<div class="container">
					<div class="row v-align-children">
						<div class="col-md-7 col-sm-6 mb-xs-24 text-center">
							<div class="embed-video-container embed-responsive embed-responsive-16by9">
								<iframe class="embed-responsive-item" src="https://www.youtube-nocookie.com/embed/DxPGkJzXZdU?showinfo=0&amp;rel=0&amp;modestbranding=1" allowfullscreen="allowfullscreen"></iframe>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section>
				<div class="container">
					<div class="row">
						<div class="col-sm-10 col-sm-offset-1">
							<h3 class="uppercase color-primary mb40 mb-xs-24">Video-rate Localization in Multiple Maps for Wearable Augmented Reality</h3>
							<p class="lead">
								<b>R O Castle</b>, G Klein, and D W Murray, Proc 12th IEEE International Symposium on Wearable Computers, Pittsburgh PA, Sept 28 &#8211; Oct 1, 2008. <span style="color: #ff0000;">This paper won the Best Paper award.</span> <a href="http://dx.doi.org/10.1109/ISWC.2008.4911577">doi:10.1109/ISWC.2008.4911577</a>
							</p>
							<p class="text-center">
								<a class="btn" href="http://www.robots.ox.ac.uk/ActiveVision/Publications/castle_etal_iswc2008/castle_etal_iswc2008.pdf">Paper</a>

								<a class="btn" href="http://www.robots.ox.ac.uk/~bob/publications/castle_etal_iswc2008/iswc_ismar_poster_2008.pdf">Demo Poster</a>
							</p>
							<h4>Abstract</h4>
							<p>
								We show how a system for video-rate parallel camera tracking and 3D map-building can be readily extended to allow one or more cameras to work in several maps, separately or simultaneously. The ability to handle several thousand features per map at video-rate, and for the cameras to switch automatically between maps, allows spatially localized AR workcells to be constructed and used with very little intervention from the user of a wearable vision system. The user can explore an environment in a natural way, acquiring local maps in real-time. When revisiting those areas the camera will select the correct local map from store and continue tracking and structural acquisition, while the user views relevant AR constructs registered to that map.
							</p>
						</div>
					</div>
				</div>
				
				<div class="container">
					<div class="row v-align-children">
						<div class="col-md-7 col-sm-6 mb-xs-24 text-center">
							<div class="embed-video-container embed-responsive embed-responsive-16by9">
								<iframe class="embed-responsive-item" src="https://www.youtube-nocookie.com/embed/4xg6nki0pfU?showinfo=0&amp;rel=0&amp;modestbranding=1" allowfullscreen="allowfullscreen"></iframe>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section>
				<div class="container">
					<div class="row">
						<div class="col-sm-10 col-sm-offset-1">
							<h3 class="uppercase color-primary mb40 mb-xs-24">Video-rate recognition and localization for wearable cameras</h3>
							<p class="lead">
								<b>R O Castle</b>, D J Gawley, G Klein, and D W Murray, Proc 18th British Machine Vision Conference, Warwick, Sept 2007. <a href="http://dx.doi.org/10.5244/C.21.112">doi:10.5244/C.21.112</a>
							</p>
							<p class="text-center">
								<a class="btn" href="http://www.robots.ox.ac.uk/ActiveVision/Publications/castle_etal_bmvc2007/castle_etal_bmvc2007.pdf">Paper</a>
							</p>
								<h4>Abstract</h4>
							<p>
								Using simultaneous localization and mapping to determine the 3D surroundings and pose of a wearable or hand-held camera provides the geometrical foundation for several capabilities of value to an autonomous wearable vision system. The one explored here is the ability to incorporate recognized objects into the map of the surroundings and refer to them. Established methods for feature cluster recognition are used to identify and localize known planar objects, and their geometry is incorporated into the map of the surrounds using a minimalist representation. Continued measurement of these mapped objects improves both the accuracy of estimated maps and the robustness of the tracking system. In the context of wearable (or hand-held) vision, the system&#8217;s ability to enhance generated maps with known objects increases the map&#8217;s value to human operators, and also enables meaningful automatic annotation of the user&#8217;s surroundings.
							</p>
						</div>
					</div>
				</div>

				<div class="container">
					<div class="row v-align-children">
						<div class="col-md-7 col-sm-6 mb-xs-24 text-center">
							<div class="embed-video-container embed-responsive embed-responsive-16by9">
								<iframe class="embed-responsive-item" src="https://www.youtube-nocookie.com/embed/j4lKuUFHHqA?showinfo=0&amp;rel=0&amp;modestbranding=1" allowfullscreen="allowfullscreen"></iframe>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section>
				<div class="container">
					<div class="row">
						<div class="col-sm-10 col-sm-offset-1">
							<h3 class="uppercase color-primary mb40 mb-xs-24">Towards simultaneous recognition, localization and mapping for hand-held and wearable cameras</h3>
							<p class="lead">
								<b>R O Castle</b>, D J Gawley, G Klein, and D W Murray, Proc. International Conference on Robotics and Automation, Rome, April 2007. <a href="http://dx.doi.org/10.1109/ROBOT.2007.364109">doi:10.1109/ROBOT.2007.364109</a>
							</p>
							<p class="text-center">
								<a class="btn" href="http://www.robots.ox.ac.uk/ActiveVision/Publications/castle_etal_icra2007/castle_etal_icra2007.pdf">Paper</a>
							</p>
							<h4>Abstract</h4>
							<p>
								This paper presents a system which combines single-camera SLAM (Simultaneous Localization and Mapping) with established methods for feature recognition. Besides using standard salient image features to build an on-line map of the camera&#8217;s environment, this system is capable of identifying and localizing known planar objects in the scene, and incorporating their geometry into the world map. Continued measurement of these mapped objects improves both the accuracy of estimated maps and the robustness of the tracking system. In the context of hand-held or wearable vision, the system&#8217;s ability to enhance generated maps with known objects increases the map&#8217;s value to human operators, and also enables meaningful automatic annotation of the user&#8217;s surroundings. The presented solution lies between the high order enriching of maps such as scene classification, and the efforts to introduce higher geometric primitives such as lines into probabilistic maps.
								<br>
							</p>
						</div>
					</div>
				</div>
				
				<div class="container">
					<div class="row v-align-children">
						<div class="col-md-7 col-sm-6 mb-xs-24 text-center">
							<div class="embed-video-container embed-responsive embed-responsive-16by9">
								<iframe class="embed-responsive-item" src="https://www.youtube-nocookie.com/embed/KhX_rLqhiaU?showinfo=0&amp;rel=0&amp;modestbranding=1" allowfullscreen="allowfullscreen"></iframe>
							</div>
						</div>
					</div>
				</div>
			</section>

			<footer class="footer-2 bg-dark text-center-xs">
				<div class="container">
					<div class="row">
						<div class="col-sm-4">
							<a href="#"><img class="image-xxs fade-half" alt="Pic" src="img/logo-light.png"></a>
						</div>
					
						<div class="col-sm-4 text-center">
							<span class="fade-half">
								© Copyright 2023 Robert Castle - All Rights Reserved
							</span>
						</div>
					
						<div class="col-sm-4 text-right text-center-xs">
							<ul class="list-inline social-list">
								<li><a href="https://github.com/robertcastle" target="_self"><i class="fa fa-github-square"></i></a></li>
								<li class="vpf"><a href="https://www.linkedin.com/in/drrobertcastle/" target="_self"><i class="fa fa-linkedin-square"></i></a></li>
							</ul>
						</div>
					</div>
				</div>
			</footer>
		</div>

		<script src="js/jquery.min.js"></script>
		<script src="js/bootstrap.min.js"></script>
		<script src="js/scripts.js"></script>
	</body>
</html>
