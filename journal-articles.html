<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<title>Journal Articles</title>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<link href="css/font-awesome.min.css" rel="stylesheet" type="text/css" media="all">
		<link href="css/themify-icons.css" rel="stylesheet" type="text/css" media="all" />
		<link href="css/bootstrap.css" rel="stylesheet" type="text/css" media="all" />
		<link href="css/theme-fire.css" rel="stylesheet" type="text/css" media="all" />
		<link href="css/custom.css" rel="stylesheet" type="text/css" media="all" />
		<link href='https://fonts.googleapis.com/css?family=Lato:300,400%7CRaleway:100,400,300,500,600,700%7COpen+Sans:400,500,600' rel='stylesheet' type='text/css'>
		<link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,600,700" rel="stylesheet" type="text/css">
		<link href="css/font-roboto.css" rel="stylesheet" type="text/css">
		<link rel="apple-touch-icon" sizes="180x180" href="/img/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="/img/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/img/favicon-16x16.png">
		<link rel="manifest" href="/site.webmanifest">
	</head>

	<body class="boxed-layout btn-rounded">
		<div class="nav-container">
			<nav>
				<div class="left big-logo">
					<a href="index.html">
					<div class="vnu" >
						<img class="logo logo-dark" title="Robert Castle" src="img/logo.png">
					</div>
					</a>
				</div>
				<div class="nav-bar">
					<div class="module widget-handle mobile-toggle right visible-sm visible-xs">
						<i class="ti-menu"></i>
					</div>
					<div class="module-group right">
						<div class="module left">
							<ul class="menu">
								<li>
									<a href="index.html" target="_self">Home</a>
								</li>
								<li class="has-dropdown toggle-sub">
									<a href="#">Publications</a>
									<ul>
										<li>
											<a href="thesis.html" target="_self">Thesis</a>
										</li>
										<li>
											<a href="conference-papers.html" target="_self">Conference papers<br></a>
										</li>
										<li>
											<a href="journal-articles.html" target="_self">Journal Articles<br></a>
										</li>
									</ul>
								</li>
								<li>
									<a href="software.html" target="_self">Software<br></a>
								</li>
								<li class="vpf">
									<a href="contact.html" target="_self">Contact</a>
								</li>
							</ul>
						</div>
					</div>
				</div>
			</nav>
		</div>
		
		<div class="main-container">
			<section class="page-title page-title-4 bg-secondary">
				<div class="container">
					<div class="row">
						<div class="col-md-6">
							<h3 class="mb0 bold">Journal Articles</h3>
						</div>
					</div>
				</div>
			</section>

			<section>
				<div class="container">
					<div class="row">
						<div class="col-sm-10 col-sm-offset-1">
							<h3 class="uppercase color-primary mb40 mb-xs-24">Keyframe-based recognition and localization during video-rate parallel tracking and mapping</h3>
							<p class="lead">
								<b>R O Castle</b>, D W Murray, Journal of Image and Vision Computing, Vol 29, No 8, pp 524-532, 2011. <a href="http://dx.doi.org/10.1016/j.imavis.2011.05.002">doi:10.1016/j.imavis.2011.05.002</a>
							</p>
							<p class="text-center">
								<a class="btn" href="http://www.robots.ox.ac.uk/ActiveVision/Publications/castle_murray_ivc2011/castle_murray_ivc2011.pdf">Paper</a>
							</p>
							<h4>Abstract</h4>
							<p>
								Generating situational awareness by augmenting live imagery with collocated scene information has applications from game-playing to military command and control. We propose a method of object recognition, reconstruction, and localization using triangulation of SIFT features from keyframe camera poses in a 3D map. The map and keyframe poses themselves are recovered at video-rate by bundle adjustment of FAST image features in the parallel tracking and mapping algorithm. Detected objects are automatically labelled on the user&#8217;s display using predefined annotations. Experimental results are given for laboratory scenes, and in more realistic applications.
								<br>
							</p>
						</div>
					</div>
				</div>
				
				<div class="container">
					<div class="row v-align-children">
						<div class="col-md-7 col-sm-6 mb-xs-24 text-center">
							<div class="embed-video-container embed-responsive embed-responsive-16by9">
								<iframe width="580" height="327" src="https://www.youtube-nocookie.com/embed/kZg5THzYRNI?list=PLNPUAmEWLgrD8jcGard9M6E86Db2dW3v1" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section>
				<div class="container">
					<div class="row">
						<div class="col-sm-10 col-sm-offset-1">
							<h3 class="uppercase color-primary mb40 mb-xs-24">Wide-area Augmented Reality using Camera Tracking and Mapping in Multiple Regions</h3>
							<p class="lead">
								<b>R O Castle</b>, G Klein and D W Murray, Journal of Computer Vision and Image Understanding, Volume 115, Issue 6, June 2011, Pages 854-867. <a href="http://dx.doi.org/10.1016/j.cviu.2011.02.007">doi:10.1016/j.cviu.2011.02.007</a>
							</p>
							<p class="text-center">
								<a class="btn" href="http://www.robots.ox.ac.uk/ActiveVision/Publications/castle_etal_cviu2011/castle_etal_cviu2011.pdf">Paper</a>
							</p>
							<h4>Abstract</h4>
							<p>
								We show how a system for video-rate parallel camera tracking and 3D map-building can be readily extended to allow one or more cameras to work in several maps, separately or simultaneously. The ability to handle several thousand features per map at video-rate, and for the cameras to switch automatically between maps, allows spatially localized AR workcells to be constructed and used with very little intervention from the user of a wearable vision system. The user can explore an environment in a natural way, acquiring local maps in real-time. When revisiting those areas the camera will select the correct local map from store and continue tracking and structural acquisition, while the user views relevant AR constructs registered to that map. The method is shown working in a progressively larger environments, from desktop to large building.
							</p>
						</div>
					</div>
				</div>
				
				<div class="container">
					<div class="row v-align-children">
						<div class="col-md-7 col-sm-6 mb-xs-24 text-center">
							<div class="embed-video-container embed-responsive embed-responsive-16by9">
								<iframe width="580" height="327" src="https://www.youtube-nocookie.com/embed/sDHN76-zueg?list=PLNPUAmEWLgrBuyuXutv-q-RWLu9Kxgui8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section>
				<div class="container">
					<div class="row">
						<div class="col-sm-10 col-sm-offset-1">
							<h3 class="uppercase color-primary mb40 mb-xs-24">Combining monoSLAM with Object Recognition for Scene Augmentation using a Wearable Camera</h3>
							<p class="lead">
								<b>R O Castle</b>, G Klein and D W Murray, Journal of Image and Vision Computing, Volume 28, Issue 11, November 2010, Pages 1548-1556. <a href="http://dx.doi.org/10.1016/j.imavis.2010.03.009">doi:10.1016/j.imavis.2010.03.009</a>
							</p>
							<p class="text-center">
								<a class="btn" href="http://www.robots.ox.ac.uk/ActiveVision/Publications/castle_etal_ivc2010/castle_etal_ivc2010.pdf">Paper</a>
							</p>	
							<h4>Abstract</h4>
							<p>
								In wearable visual computing, maintaining a time-evolving representation of the 3D environment along with the pose of the camera provides the geometrical foundation on which person-centred processing can be built. In this paper, an established method for the recognition of feature clusters is used on live imagery to identify and locate planar objects around the wearer. Objects&#8217; locations are incorporated as additional 3D measurements into a monocular simultaneous localization and mapping process, which routinely uses 2D image measurements to acquire and maintain a map of the surroundings, irrespective of whether objects are present or not. Augmenting the 3D maps with automatically recognized objects enables useful annotations of the surroundings to be presented to the wearer. After demonstrating the geometrical integrity of the method, experiments show its use in two augmented reality applications.
							</p>
						</div>
					</div>
				</div>
				
				<div class="container">
					<div class="row v-align-children">
						<div class="col-md-7 col-sm-6 mb-xs-24 text-center">
							<div class="embed-video-container embed-responsive embed-responsive-16by9">
								<iframe width="580" height="327" src="https://www.youtube-nocookie.com/embed/x8KJ4L6tGI8?list=PLNPUAmEWLgrBtHYGoUnYC2YAZdw9DacGg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
							</div>
						</div>
					</div>
				</div>
			</section>

			<footer class="footer-2 bg-dark text-center-xs">
				<div class="container">
					<div class="row">
						<div class="col-sm-4">
							<a href="#"><img class="image-xxs fade-half" alt="Pic" src="img/logo-light.png"></a>
						</div>
					
						<div class="col-sm-4 text-center">
							<span class="fade-half">
								Â© Copyright 2022 Robert Castle - All Rights Reserved
							</span>
						</div>
					
						<div class="col-sm-4 text-right text-center-xs">
							<ul class="list-inline social-list">
								<li><a href="https://github.com/robertcastle" target="_self"><i class="fa fa-github-square"></i></a></li>
								<li class="vpf"><a href="https://www.linkedin.com/in/drrobertcastle/" target="_self"><i class="fa fa-linkedin-square"></i></a></li>
							</ul>
						</div>
					</div>
				</div>
			</footer>
		</div>

		<script src="js/jquery.min.js"></script>
		<script src="js/bootstrap.min.js"></script>
		<script src="js/scripts.js"></script>
	</body>
</html>
